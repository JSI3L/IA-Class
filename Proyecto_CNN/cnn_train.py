import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import os
import sys
from pathlib import Path

# Verificar y crear estructura de directorios
def setup_directories():
    base_dirs = ['data/train', 'data/validation']
    classes = ['catarina', 'hormiga', 'perro', 'gato', 'tortuga']
    
    for base_dir in base_dirs:
        if not os.path.exists(base_dir):
            print(f"Creando directorio: {base_dir}")
            os.makedirs(base_dir, exist_ok=True)
        
        for class_name in classes:
            class_dir = os.path.join(base_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"Creando directorio de clase: {class_dir}")
                os.makedirs(class_dir, exist_ok=True)
    
    print("\nEstructura de directorios creada.")
    print("Por favor, coloca tus im√°genes en las carpetas correspondientes:")
    print("  - data/train/[clase]/")
    print("  - data/validation/[clase]/")
    print("\nClases: catarina, hormiga, perro, gato, tortuga")

# Configuraci√≥n
IMG_SIZE = (128, 128)
BATCH_SIZE = 16  # Reducido para datasets peque√±os
EPOCHS = 15  # Reducido temporalmente
NUM_CLASSES = 5

# Rutas del dataset
train_dir = 'data/train'
validation_dir = 'data/validation'

# Verificar si existen los directorios
if not os.path.exists(train_dir):
    print(f"ERROR: No se encuentra el directorio: {train_dir}")
    print("\nCreando estructura de directorios...")
    setup_directories()
    print("\nPor favor, coloca tus im√°genes en las carpetas y vuelve a ejecutar.")
    sys.exit(1)

# Verificar im√°genes en cada directorio
def count_images_in_directory(directory_path):
    """Cuenta im√°genes en un directorio y sus subdirectorios"""
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')
    count = 0
    class_counts = {}
    
    if not os.path.exists(directory_path):
        return 0, {}
    
    for class_name in os.listdir(directory_path):
        class_path = os.path.join(directory_path, class_name)
        if os.path.isdir(class_path):
            class_images = 0
            for file in os.listdir(class_path):
                if file.lower().endswith(image_extensions):
                    class_images += 1
                    count += 1
            class_counts[class_name] = class_images
    
    return count, class_counts

print("=== VERIFICACI√ìN DE IM√ÅGENES ===")
train_count, train_class_counts = count_images_in_directory(train_dir)
val_count, val_class_counts = count_images_in_directory(validation_dir)

print(f"\nIm√°genes en train: {train_count}")
for class_name, count in train_class_counts.items():
    print(f"  {class_name}: {count} im√°genes")

print(f"\nIm√°genes en validation: {val_count}")
for class_name, count in val_class_counts.items():
    print(f"  {class_name}: {count} im√°genes")

# Verificar si hay suficientes im√°genes
MIN_IMAGES_PER_CLASS = 5  # M√≠nimo absoluto
MIN_TOTAL_IMAGES = 20

if train_count == 0:
    print("\n‚ùå ERROR: No hay im√°genes en el directorio de entrenamiento.")
    print("Por favor, agrega im√°genes en formato JPG, PNG, etc.")
    print("Ejemplo de estructura esperada:")
    print("  data/train/catarina/imagen1.jpg")
    print("  data/train/catarina/imagen2.jpg")
    print("  ... etc.")
    sys.exit(1)

if val_count == 0:
    print("\n‚ö†Ô∏è ADVERTENCIA: No hay im√°genes en el directorio de validaci√≥n.")
    print("Usando todas las im√°genes para entrenamiento (sin validaci√≥n separada).")
    validation_dir = train_dir  # Usar mismo directorio para validaci√≥n

# Ajustar batch_size si hay pocas im√°genes
if train_count < BATCH_SIZE * 2:
    BATCH_SIZE = max(4, train_count // 2)  # Batch_size m√≠nimo de 4
    print(f"\n‚ö†Ô∏è Dataset peque√±o. Ajustando batch_size a: {BATCH_SIZE}")

# Verificar clases
classes_in_train = set(train_class_counts.keys())
if len(classes_in_train) < 2:
    print(f"\n‚ùå ERROR: Se necesitan al menos 2 clases diferentes.")
    print(f"Clases encontradas: {list(classes_in_train)}")
    sys.exit(1)

print(f"\n‚úÖ Dataset verificado: {train_count} im√°genes de entrenamiento, {val_count} im√°genes de validaci√≥n")

# Data augmentation para entrenamiento
print("\nConfigurando data augmentation...")
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 if val_count == 0 else 0.0  # Split si no hay validation separado
)

# Solo reescalar para validaci√≥n
validation_datagen = ImageDataGenerator(rescale=1./255)

print("Creando generadores de datos...")
try:
    # Si no hay directorio de validaci√≥n separado, usar split del train
    if val_count == 0:
        print("Usando 80% para entrenamiento, 20% para validaci√≥n...")
        train_generator = train_datagen.flow_from_directory(
            train_dir,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training'
        )
        
        validation_generator = train_datagen.flow_from_directory(
            train_dir,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation'
        )
    else:
        # Usar directorios separados
        train_generator = train_datagen.flow_from_directory(
            train_dir,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical'
        )
        
        validation_generator = validation_datagen.flow_from_directory(
            validation_dir,
            target_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical'
        )
    
    print("‚úÖ Generadores creados exitosamente")
    
except Exception as e:
    print(f"‚ùå Error al crear generadores: {e}")
    print("\nPosibles soluciones:")
    print("1. Verifica que cada carpeta de clase tiene al menos una imagen")
    print("2. Aseg√∫rate de que las im√°genes tienen formatos v√°lidos (.jpg, .png, etc.)")
    print("3. Intenta con menos clases si tienes pocas im√°genes")
    sys.exit(1)

# Verificar las clases encontradas
class_names = list(train_generator.class_indices.keys())
print(f"\n‚úÖ Clases encontradas: {class_names}")
print(f"üìä Total de clases: {len(class_names)}")
print(f"üìä N√∫mero de im√°genes de entrenamiento: {train_generator.samples}")
print(f"üìä N√∫mero de im√°genes de validaci√≥n: {validation_generator.samples}")

# Ajustar steps por √©poca
steps_per_epoch = max(1, train_generator.samples // BATCH_SIZE)
validation_steps = max(1, validation_generator.samples // BATCH_SIZE)

print(f"\n‚öôÔ∏è  Configuraci√≥n de entrenamiento:")
print(f"   Batch size: {BATCH_SIZE}")
print(f"   Steps por √©poca: {steps_per_epoch}")
print(f"   Validation steps: {validation_steps}")

# Construcci√≥n del modelo CNN m√°s simple para dataset peque√±o
print("\nConstruyendo modelo CNN...")
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D(2, 2),
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    
    layers.Flatten(),
    layers.Dropout(0.3),  # Reducido para dataset peque√±o
    layers.Dense(128, activation='relu'),  # Reducido
    layers.Dense(len(class_names), activation='softmax')
])

# Compilar el modelo
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Tasa de aprendizaje m√°s baja
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("‚úÖ Modelo construido y compilado")
model.summary()

# Callbacks para mejorar el entrenamiento
callbacks = [
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=3,
        restore_best_weights=True,
        verbose=1
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=2,
        min_lr=0.00001,
        verbose=1
    ),
    tf.keras.callbacks.ModelCheckpoint(
        'best_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# Entrenamiento
print(f"\nüöÄ Iniciando entrenamiento por {EPOCHS} √©pocas...")
print("   Esto puede tomar unos minutos...")

try:
    history = model.fit(
        train_generator,
        steps_per_epoch=steps_per_epoch,
        epochs=EPOCHS,
        validation_data=validation_generator,
        validation_steps=validation_steps,
        callbacks=callbacks,
        verbose=1
    )
    
    print("‚úÖ Entrenamiento completado exitosamente!")
    
except Exception as e:
    print(f"‚ùå Error durante el entrenamiento: {e}")
    print("\nüí° Posibles soluciones:")
    print("   1. Reduce a√∫n m√°s el batch_size (ej: 8 o 4)")
    print("   2. Reduce el tama√±o de las im√°genes (ej: 100x100)")
    print("   3. Agrega m√°s im√°genes a tu dataset")
    print("   4. Verifica que todas las im√°genes se puedan leer")
    
    # Intentar con batch_size m√°s peque√±o
    print("\nüîÑ Intentando con batch_size=8...")
    BATCH_SIZE = 8
    steps_per_epoch = max(1, train_generator.samples // BATCH_SIZE)
    validation_steps = max(1, validation_generator.samples // BATCH_SIZE)
    
    train_generator.batch_size = BATCH_SIZE
    validation_generator.batch_size = BATCH_SIZE
    
    try:
        history = model.fit(
            train_generator,
            steps_per_epoch=steps_per_epoch,
            epochs=10,  # Menos √©pocas
            validation_data=validation_generator,
            validation_steps=validation_steps,
            callbacks=callbacks,
            verbose=1
        )
        print("‚úÖ Entrenamiento completado con batch_size=8!")
    except Exception as e2:
        print(f"‚ùå Error persistente: {e2}")
        print("\nüéØ Soluci√≥n definitiva: Agrega m√°s im√°genes a tu dataset.")
        print("   Necesitas al menos 10-20 im√°genes por clase para empezar.")
        sys.exit(1)

# Guardar el modelo final
model.save('animal_classifier_model.h5')
print("üíæ Modelo guardado como 'animal_classifier_model.h5'")

# Guardar las etiquetas de clase
import pickle
with open('class_labels.pkl', 'wb') as f:
    pickle.dump(class_names, f)
print("üè∑Ô∏è  Etiquetas guardadas como 'class_labels.pkl'")

# Gr√°ficas de precisi√≥n y p√©rdida
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Precisi√≥n entrenamiento', marker='o')
plt.plot(history.history['val_accuracy'], label='Precisi√≥n validaci√≥n', marker='s')
plt.title('Precisi√≥n del modelo')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='P√©rdida entrenamiento', marker='o')
plt.plot(history.history['val_loss'], label='P√©rdida validaci√≥n', marker='s')
plt.title('P√©rdida del modelo')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('training_history.png', dpi=100)
print("üìä Gr√°ficas guardadas como 'training_history.png'")
plt.show()

# Evaluaci√≥n final
print("\nüìà Evaluando modelo final...")
test_loss, test_acc = model.evaluate(validation_generator, verbose=0)
print(f"üéØ Precisi√≥n en validaci√≥n: {test_acc:.2%}")

# Mostrar resumen
print("\n" + "="*50)
print("üéâ RESUMEN DEL ENTRENAMIENTO")
print("="*50)
print(f"üìÅ Clases: {', '.join(class_names)}")
print(f"üìä Im√°genes de entrenamiento: {train_count}")
print(f"üìä Im√°genes de validaci√≥n: {val_count if val_count > 0 else '20% del train'}")
print(f"üéØ Precisi√≥n final: {test_acc:.2%}")
print(f"üíæ Modelo guardado: animal_classifier_model.h5")
print(f"üè∑Ô∏è  Etiquetas guardadas: class_labels.pkl")
print("="*50)
print("\n‚úÖ ¬°Listo! Ahora puedes usar el modelo para predecir.")
print("   Ejecuta: python predict.py")